---
title: "Statistical Analysis and Results"
format: 
  docx:
    toc: false
    number-sections: true
    highlight-style: github
    prefer-html: true
bibliography: references.bib
csl: apa.csl
---

```{r} 
#| message: false
#| warning: false
#| echo: false
#| include: false

knitr::opts_chunk$set(echo = TRUE, fig.align="center")
options(knitr.kable.NA = '')

library(tidyverse)
library(kableExtra)
library(patchwork)

```

# Statistical Analysis

Statistical analysis of the data extracted was performed in R, (v 4.3.3; R Core Team, https://www.r-project.org/) and RStudio (v 2023.06.1; Posit, https://posit.co/). All code utilised for data preparation and analyses are available in either the Open Science Framework page for this project [https://osf.io/5fjq3/](https://osf.io/5fjq3/) or the corresponding GitHub repository [https://github.com/jamessteeleii/older_adults_RT_machines_MA](https://github.com/jamessteeleii/older_adults_RT_machines_MA). The present analysis was not pre-registered as we had no a priori hypotheses and thus, given the pilot nature of this study, was considered exploratory and aimed at parameter estimation [@cummingNewStatisticsWhy2014] within a Bayesian meta-analytic framework [@kruschkeBayesianNewStatistics2018]. For all analyses model parameter estimates and their precision, along with conclusions based upon them, were interpreted continuously and probabilistically, considering data quality, plausibility of effect, and previous literature, all within the context of each model. The `renv` package [@usheyRenvProjectEnvironments2023] was used for package version reproducibility and a function based analysis pipeline using the `targets` package [@landauTargetsDynamicFunctionOriented2023] was employed (the analysis pipeline can be viewed by downloading the R Project and running the function `targets::tar_visnetwork()`). Standardised effect sizes were all calculated using the `metafor` package [@viechtbauerMetaforMetaAnalysisPackage2023]. The main package `brms` [@burknerBrmsBayesianRegression2023] was used in fitting all the Bayesian meta-analysis models. Prior and posterior draws were taken using `tidybayes` [@kayTidybayesTidyData2023] and `marginaleffects` [@arel-bundockMarginaleffectsPredictionsComparisons2023] packages. All visualisations were created using `ggplot2` [@wickhamGgplot2CreateElegant2023], `tidybayes`, and the `patchwork` [@pedersenPatchworkComposerPlots2023] packages. Where data to be extracted from included studies was reported in plots only we used the `juicr` package to extract this data [@lajeunesseJuicrAutomatedManual2021] and the reproducible reports for this can be found in the online supplementary materials.

As noted, we adopted a Bayesian approach to the present meta-analysis. Specifically, we adopted an arm-based multiple treatment comparison (i.e., network) type model given that for the studies identified some, but not all, included a non-training control arm in addition to the machine-based RT arm [@hongBayesianMissingData2016]. In typical contrast-based meta-analyses data is limited to the effect sizes for paired contrasts between arm and thus studies that include both arm (i.e., relative effects between non-training control vs machine based RT conditions); however, in arm-based analyses the data are the absolute effects within each arm and information is borrowed across studies to enable both within condition absolute, and between condition relative contrasts to be estimated. As in the present analysis we are only comparing two conditions we do not examine ranking methods as are typical in multiple treatment comparison models, but instead we focus on reporting the between condition relative contrast for non-training control vs machine-based RT. We fit two models: one for all function outcomes reported and one for all strength outcomes reported. Pre- to post-intervention period standardised effect sizes were calculated using Becker's $d$ [@beckerSynthesizingStandardizedMeanchange1988] for each outcome within each arm within each study. As such, data were hierarchical across three levels (i.e., effects within arms within studies) and so we included random intercepts using implicit nested coding across these levels. Given the arm-based model, we included a fixed categorical predictor using dummy coding indicating which condition a given arm within the study belonged to (i.e., non-training control or machine-based RT where the former was the intercept) and also allowed for this to be a random effect to enable the partial pooling of information across studies where there were not direct between condition relative contrasts present. We did not have any prior intuition or data available for the specific intervention in this population that was not included in the likelihood for the model anyway and so we adopted uninformed default weakly regularising priors for all parameters. We fit each model using four Monte Carlo Markov Chains each with 2000 warmup and 6000 sampling iterations. Trace plots were produced along with $\hat{R}$ values to examine whether chains had converged, and posterior predictive checks for each model were also examined to understand the model implied distributions. These all showed good convergence with all $\hat{R}$ values close to 1 and  posterior predictive checks seemed appropriate distributions for the observed data (all diagnostic plots can be seen in the supplementary materials: [https://osf.io/z9u7s](https://osf.io/z9u7s)). From each model we obtained draws from the posterior distributions for the conditional absolute estimates for each condition by study, the global grand mean absolute estimates for each condition, and the between condition relative contrast for non-training control vs machine-based RT in order to present probability density functions visually, and also to calculate mean and 95% quantile intervals (i.e., 'credible' or 'compatibility' intervals) for each estimate. These gave us the most probable value of the parameter in addition to the range from 2.5% to 97.5% percentiles. 

# Results
```{r}
#| message: false
#| warning: false
#| echo: false

targets::tar_load(
  c(
  model_function,
  tidy_model_function,
  study_function_plot,
  meta_function_plot,
  contrast_function_plot,
  model_strength,
  tidy_model_strength,
  study_strength_plot,
  meta_strength_plot,
  contrast_strength_plot
  )
)

tidy_model_function <- tidy_model_function |>
  mutate(across(where(is.numeric), round, 2))

tidy_model_strength <- tidy_model_strength |>
  mutate(across(where(is.numeric), round, 2))


n_conditions_function <- model_function$data |> group_by(study_code, training_control) |> slice_head() |> ungroup() |> count(training_control)
  

n_conditions_strength <- model_strength$data |> group_by(study_code, training_control) |> slice_head() |> ungroup() |> count(training_control)

```

## Functional Outcomes
The model examining functional outcomes included `r length(unique(model_function$data$study_code))` studies containing `r length(unique(model_function$data$group_code))` separate arms (`r n_conditions_function[1,2]` non-training control and `r n_conditions_function[2,2]` machine-based RT) reporting `r length(unique(model_function$data$es_code))` within arm effects. The global grand mean estimate for the between condition relative contrast (i.e., machine-based RT minus non-training control) was `r tidy_model_function$estimate[2]` [95% credible interval: `r tidy_model_function$conf.low[2]`,`r tidy_model_function$conf.high[2]`], though there was considerable heterogeneity in the magnitude of effects between studies ($\tau^2_{Condition (training)}$ = `r tidy_model_function$estimate[6]` [95% credible interval: `r tidy_model_function$conf.low[6]`,`r tidy_model_function$conf.high[6]`]). An ordered forest plot of conditional study level estimates for absolute within condition effects, the global grand mean estimates for absolute within condition effects, and the global grand mean estimate for the between condition relative contrast including interval estimates and posterior probability distributions are shown in @fig-function-model

```{r}
#| message: false
#| warning: false
#| echo: false
#| label: fig-function-model 
#| fig-width: 10
#| fig-height: 10
#| fig-cap: An ordered forest plot for functional outcomes of conditional study level estimates for absolute within condition effects including individual effect sizes as points (top panel), the global grand mean estimates for absolute within condition effects (bottom left panel), and the global grand mean estimate for the between condition relative contrast (top right panel) including interval estimates and posterior probability distributions

(study_function_plot / (meta_function_plot + contrast_function_plot)) + 
    plot_annotation(title = "Meta-Analysis of Prior Studies Examining the Effects of Machine Based Resistance Training on Function",
                    caption = "Point estimates and 95% quantile intervals reported") +
    plot_layout(guides = "collect", axis_titles = "collect",
                widths = c(2,1,1))  &
    theme(axis.title.x = element_text(size=10),
          legend.position = "bottom")
```

## Strength Outcomes
The model examining strength outcomes included `r length(unique(model_strength$data$study_code))` studies containing `r length(unique(model_strength$data$group_code))` separate arms (`r n_conditions_strength[1,2]` non-training control and `r n_conditions_strength[2,2]` machine-based RT) reporting `r length(unique(model_strength$data$es_code))` within arm effects. The global grand mean estimate for the between condition relative contrast (i.e., machine-based RT minus non-training control) was `r tidy_model_strength$estimate[2]` [95% credible interval: `r tidy_model_strength$conf.low[2]`,`r tidy_model_strength$conf.high[2]`], though there was considerable heterogeneity in the magnitude of effects between studies ($\tau^2_{Condition (training)}$ = `r tidy_model_strength$estimate[6]` [95% credible interval: `r tidy_model_strength$conf.low[6]`,`r tidy_model_strength$conf.high[6]`]). An ordered forest plot of conditional study level estimates for absolute within condition effects, the global grand mean estimates for absolute within condition effects, and the global grand mean estimate for the between condition relative contrast including interval estimates and posterior probability distributions are shown in @fig-strength-model

```{r}
#| message: false
#| warning: false
#| echo: false
#| label: fig-strength-model 
#| fig-width: 10
#| fig-height: 10
#| fig-cap: An ordered forest plot for strength outcomes of conditional study level estimates for absolute within condition effects including individual effect sizes as points (top panel), the global grand mean estimates for absolute within condition effects (bottom left panel), and the global grand mean estimate for the between condition relative contrast (top right panel) including interval estimates and posterior probability distributions

(study_strength_plot / (meta_strength_plot + contrast_strength_plot)) + 
    plot_annotation(title = "Meta-Analysis of Prior Studies Examining the Effects of Machine Based Resistance Training on Strength",
                    caption = "Point estimates and 95% quantile intervals reported") +
    plot_layout(guides = "collect", axis_titles = "collect",
                widths = c(2,1,1))  &
    theme(axis.title.x = element_text(size=10),
          legend.position = "bottom")
```

# References
