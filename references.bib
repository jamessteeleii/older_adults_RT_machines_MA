@misc{arel-bundockMarginaleffectsPredictionsComparisons2023,
  title = {Marginaleffects: {{Predictions}}, {{Comparisons}}, {{Slopes}}, {{Marginal Means}}, and {{Hypothesis Tests}}},
  shorttitle = {Marginaleffects},
  author = {{Arel-Bundock}, Vincent and {cre} and {cph} and Diniz, Marcio Augusto and Greifer, Noah and Bacher, Etienne},
  year = {2023},
  month = oct,
  urldate = {2023-11-08},
  abstract = {Compute and plot predictions, slopes, marginal means, and comparisons (contrasts, risk ratios, odds, etc.) for over 100 classes of statistical and machine learning models in R. Conduct linear and non-linear hypothesis tests, or equivalence tests. Calculate uncertainty estimates using the delta method, bootstrapping, or simulation-based inference.},
  copyright = {GPL ({$\geq$} 3)},
  keywords = {CausalInference,Econometrics,MixedModels}
}

@article{beckerSynthesizingStandardizedMeanchange1988,
  title = {Synthesizing Standardized Mean-Change Measures},
  author = {Becker, Betsy Jane},
  year = {1988},
  journal = {British Journal of Mathematical and Statistical Psychology},
  volume = {41},
  number = {2},
  pages = {257--278},
  issn = {2044-8317},
  doi = {10.1111/j.2044-8317.1988.tb00901.x},
  urldate = {2024-04-22},
  abstract = {A new approach is presented for the meta-analysis of data from pre-test-post-test designs. With this approach, data from studies using different designs may be compared directly and studies without control groups need not be omitted. The approach is based on a `standardized mean-change' measure, computed for each sample within a study, and involves analysis of the standardized mean changes and differences in the standardized mean changes. Analyses are illustrated using results of studies of the effectiveness of mental practice on motor-skill development.},
  copyright = {1988 The British Psychological Society},
  langid = {english},
  file = {C:\Users\james\Zotero\storage\RHYLXH78\j.2044-8317.1988.tb00901.html}
}

@misc{burknerBrmsBayesianRegression2023,
  title = {Brms: {{Bayesian Regression Models}} Using '{{Stan}}'},
  shorttitle = {Brms},
  author = {B{\"u}rkner, Paul-Christian and Gabry, Jonah and Weber, Sebastian and Johnson, Andrew and Modrak, Martin and Badr, Hamada S. and Weber, Frank and {Ben-Shachar}, Mattan S. and Rabel, Hayden and Mills, Simon C. and Wild, Stephen},
  year = {2023},
  month = sep,
  urldate = {2023-11-08},
  abstract = {Fit Bayesian generalized (non-)linear multivariate multilevel models using 'Stan' for full Bayesian inference. A wide range of distributions and link functions are supported, allowing users to fit -- among others -- linear, robust linear, count data, survival, response times, ordinal, zero-inflated, hurdle, and even self-defined mixture models all in a multilevel context. Further modeling options include both theory-driven and data-driven non-linear terms, auto-correlation structures, censoring and truncation, meta-analytic standard errors, and quite a few more. In addition, all parameters of the response distribution can be predicted in order to perform distributional regression. Prior specifications are flexible and explicitly encourage users to apply prior distributions that actually reflect their prior knowledge. Models can easily be evaluated and compared using several methods assessing posterior or prior predictions. References: B{\"u}rkner (2017) {$<$}doi:10.18637/jss.v080.i01{$>$}; B{\"u}rkner (2018) {$<$}doi:10.32614/RJ-2018-017{$>$}; B{\"u}rkner (2021) {$<$}doi:10.18637/jss.v100.i05{$>$}; Carpenter et al. (2017) {$<$}doi:10.18637/jss.v076.i01{$>$}.},
  copyright = {GPL-2},
  keywords = {Bayesian,MetaAnalysis,MixedModels,Phylogenetics}
}

@article{cummingNewStatisticsWhy2014,
  title = {The {{New Statistics}}: {{Why}} and {{How}}},
  shorttitle = {The {{New Statistics}}},
  author = {Cumming, Geoff},
  year = {2014},
  month = jan,
  journal = {Psychological Science},
  volume = {25},
  number = {1},
  pages = {7--29},
  publisher = {SAGE Publications Inc},
  issn = {0956-7976},
  doi = {10.1177/0956797613504966},
  urldate = {2022-10-05},
  abstract = {We need to make substantial changes to how we conduct research. First, in response to heightened concern that our published research literature is incomplete and untrustworthy, we need new requirements to ensure research integrity. These include prespecification of studies whenever possible, avoidance of selection and other inappropriate data-analytic practices, complete reporting, and encouragement of replication. Second, in response to renewed recognition of the severe flaws of null-hypothesis significance testing (NHST), we need to shift from reliance on NHST to estimation and other preferred techniques. The new statistics refers to recommended practices, including estimation based on effect sizes, confidence intervals, and meta-analysis. The techniques are not new, but adopting them widely would be new for many researchers, as well as highly beneficial. This article explains why the new statistics are important and offers guidance for their use. It describes an eight-step new-statistics strategy for research with integrity, which starts with formulation of research questions in estimation terms, has no place for NHST, and is aimed at building a cumulative quantitative discipline.},
  langid = {english},
  file = {C:\Users\james\Zotero\storage\V346TNH8\Cumming - 2014 - The New Statistics Why and How.pdf}
}

@article{hongBayesianMissingData2016,
  title = {A {{Bayesian}} Missing Data Framework for Generalized Multiple Outcome Mixed Treatment Comparisons},
  author = {Hong, Hwanhee and Chu, Haitao and Zhang, Jing and Carlin, Bradley P.},
  year = {2016},
  journal = {Research Synthesis Methods},
  volume = {7},
  number = {1},
  pages = {6--22},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1153},
  urldate = {2024-04-22},
  abstract = {Bayesian statistical approaches to mixed treatment comparisons (MTCs) are becoming more popular because of their flexibility and interpretability. Many randomized clinical trials report multiple outcomes with possible inherent correlations. Moreover, MTC data are typically sparse (although richer than standard meta-analysis, comparing only two treatments), and researchers often choose study arms based upon which treatments emerge as superior in previous trials. In this paper, we summarize existing hierarchical Bayesian methods for MTCs with a single outcome and introduce novel Bayesian approaches for multiple outcomes simultaneously, rather than in separate MTC analyses. We do this by incorporating partially observed data and its correlation structure between outcomes through contrast-based and arm-based parameterizations that consider any unobserved treatment arms as missing data to be imputed. We also extend the model to apply to all types of generalized linear model outcomes, such as count or continuous responses. We offer a simulation study under various missingness mechanisms (e.g., missing completely at random, missing at random, and missing not at random) providing evidence that our models outperform existing models in terms of bias, mean squared error, and coverage probability then illustrate our methods with a real MTC dataset. We close with a discussion of our results, several contentious issues in MTC analysis, and a few avenues for future methodological development. Copyright {\copyright} 2015 John Wiley \& Sons, Ltd.},
  copyright = {Copyright {\copyright} 2015 John Wiley \& Sons, Ltd.},
  langid = {english},
  keywords = {Bayesian hierarchical model,Markov chain Monte Carlo,missingness mechanism,network meta-analysis},
  file = {C\:\\Users\\james\\Zotero\\storage\\65AUDZHB\\Hong et al. - 2016 - A Bayesian missing data framework for generalized .pdf;C\:\\Users\\james\\Zotero\\storage\\H7W5INHT\\jrsm.html}
}

@misc{kayTidybayesTidyData2023,
  title = {Tidybayes: {{Tidy Data}} and '{{Geoms}}' for {{Bayesian Models}}},
  shorttitle = {Tidybayes},
  author = {Kay, Matthew and Mastny, Timothy},
  year = {2023},
  month = aug,
  urldate = {2023-11-08},
  abstract = {Compose data for and extract, manipulate, and visualize posterior draws from Bayesian models ('JAGS', 'Stan', 'rstanarm', 'brms', 'MCMCglmm', 'coda', ...) in a tidy data format. Functions are provided to help extract tidy data frames of draws from Bayesian models and that generate point summaries and intervals in a tidy format. In addition, 'ggplot2' 'geoms' and 'stats' are provided for common visualization primitives like points with multiple uncertainty intervals, eye plots (intervals plus densities), and fit curves with multiple, arbitrary uncertainty bands.},
  copyright = {GPL ({$\geq$} 3)}
}

@article{kruschkeBayesianNewStatistics2018,
  title = {The {{Bayesian New Statistics}}: {{Hypothesis}} Testing, Estimation, Meta-Analysis, and Power Analysis from a {{Bayesian}} Perspective},
  shorttitle = {The {{Bayesian New Statistics}}},
  author = {Kruschke, John K. and Liddell, Torrin M.},
  year = {2018},
  month = feb,
  journal = {Psychonomic Bulletin \& Review},
  volume = {25},
  number = {1},
  pages = {178--206},
  issn = {1531-5320},
  doi = {10.3758/s13423-016-1221-4},
  urldate = {2022-10-05},
  abstract = {In the practice of data analysis, there is a conceptual distinction between hypothesis testing, on the one hand, and estimation with quantified uncertainty on the other. Among frequentists in psychology, a shift of emphasis from hypothesis testing to estimation has been dubbed ``the New Statistics'' (Cumming 2014). A second conceptual distinction is between frequentist methods and Bayesian methods. Our main goal in this article is to explain how Bayesian methods achieve the goals of the New Statistics better than frequentist methods. The article reviews frequentist and Bayesian approaches to hypothesis testing and to estimation with confidence or credible intervals. The article also describes Bayesian approaches to meta-analysis, randomized controlled trials, and power analysis.},
  langid = {english},
  keywords = {Bayes factor,Bayesian inference,Confidence interval,Credible interval,Effect size,Equivalence testing,Highest density interval,Meta-analysis,Null hypothesis significance testing,Power analysis,Randomized controlled trial,Region of practical equivalence},
  file = {C:\Users\james\Zotero\storage\ZC6EX7YU\Kruschke and Liddell - 2018 - The Bayesian New Statistics Hypothesis testing, e.pdf}
}

@misc{lajeunesseJuicrAutomatedManual2021,
  title = {Juicr: {{Automated}} and {{Manual Extraction}} of {{Numerical Data}} from {{Scientific Images}}},
  shorttitle = {Juicr},
  author = {Lajeunesse, Marc J.},
  year = {2021},
  month = apr,
  urldate = {2024-04-22},
  abstract = {Provides a GUI interface for automating data extraction from multiple images containing scatter and bar plots, semi-automated tools to tinker with extraction attempts, and a fully-loaded point-and-click manual extractor with image zoom, calibrator, and classifier. Also provides detailed and R-independent extraction reports as fully-embedded .html records.},
  copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords = {MetaAnalysis}
}

@misc{landauTargetsDynamicFunctionOriented2023,
  title = {Targets: {{Dynamic Function-Oriented}} '{{Make}}'-{{Like Declarative Pipelines}}},
  shorttitle = {Targets},
  author = {Landau, William Michael and Warkentin, Matthew T. and Edmondson, Mark and Oliver, Samantha and Mahr, Tristan and and Company, Eli Lilly},
  year = {2023},
  month = oct,
  urldate = {2023-11-08},
  abstract = {Pipeline tools coordinate the pieces of computationally demanding analysis projects. The 'targets' package is a 'Make'-like pipeline tool for statistics and data science in R. The package skips costly runtime for tasks that are already up to date, orchestrates the necessary computation with implicit parallel computing, and abstracts files as R objects. If all the current output matches the current upstream code and data, then the whole pipeline is up to date, and the results are more trustworthy than otherwise. The methodology in this package borrows from GNU 'Make' (2015, ISBN:978-9881443519) and 'drake' (2018, {$<$}doi:10.21105/joss.00550{$>$}).},
  copyright = {MIT + file LICENSE},
  keywords = {HighPerformanceComputing,ReproducibleResearch}
}

@misc{pedersenPatchworkComposerPlots2023,
  title = {Patchwork: {{The Composer}} of {{Plots}}},
  shorttitle = {Patchwork},
  author = {Pedersen, Thomas Lin},
  year = {2023},
  month = aug,
  urldate = {2023-11-08},
  abstract = {The 'ggplot2' package provides a strong API for sequentially building up a plot, but does not concern itself with composition of multiple plots. 'patchwork' is a package that expands the API to allow for arbitrarily complex composition of plots by, among others, providing mathematical operators for combining multiple plots. Other packages that try to address this need (but with a different approach) are 'gridExtra' and 'cowplot'.},
  copyright = {MIT + file LICENSE}
}

@misc{usheyRenvProjectEnvironments2023,
  title = {Renv: {{Project Environments}}},
  shorttitle = {Renv},
  author = {Ushey, Kevin and {cre} and Wickham, Hadley and Software, Posit and PBC},
  year = {2023},
  month = sep,
  urldate = {2023-11-08},
  abstract = {A dependency management toolkit for R. Using 'renv', you can create and manage project-local R libraries, save the state of these libraries to a 'lockfile', and later restore your library as required. Together, these tools can help make your projects more isolated, portable, and reproducible.},
  copyright = {MIT + file LICENSE},
  keywords = {ReproducibleResearch}
}

@misc{viechtbauerMetaforMetaAnalysisPackage2023,
  title = {Metafor: {{Meta-Analysis Package}} for {{R}}},
  shorttitle = {Metafor},
  author = {Viechtbauer, Wolfgang},
  year = {2023},
  month = sep,
  urldate = {2023-11-08},
  abstract = {A comprehensive collection of functions for conducting meta-analyses in R. The package includes functions to calculate various effect sizes or outcome measures, fit equal-, fixed-, random-, and mixed-effects models to such data, carry out moderator and meta-regression analyses, and create various types of meta-analytical plots (e.g., forest, funnel, radial, L'Abbe, Baujat, bubble, and GOSH plots). For meta-analyses of binomial and person-time data, the package also provides functions that implement specialized methods, including the Mantel-Haenszel method, Peto's method, and a variety of suitable generalized linear (mixed-effects) models (i.e., mixed-effects logistic and Poisson regression models). Finally, the package provides functionality for fitting meta-analytic multivariate/multilevel models that account for non-independent sampling errors and/or true effects (e.g., due to the inclusion of multiple treatment studies, multiple endpoints, or other forms of clustering). Network meta-analyses and meta-analyses accounting for known correlation structures (e.g., due to phylogenetic relatedness) can also be conducted. An introduction to the package can be found in Viechtbauer (2010) {$<$}doi:10.18637/jss.v036.i03{$>$}.},
  copyright = {GPL-2 {\textbar} GPL-3 [expanded from: GPL ({$\geq$} 2)]},
  keywords = {ClinicalTrials,MetaAnalysis,Phylogenetics}
}

@misc{wickhamGgplot2CreateElegant2023,
  title = {Ggplot2: {{Create Elegant Data Visualisations Using}} the {{Grammar}} of {{Graphics}}},
  shorttitle = {Ggplot2},
  author = {Wickham, Hadley and Chang, Winston and Henry, Lionel and Pedersen, Thomas Lin and Takahashi, Kohske and Wilke, Claus and Woo, Kara and Yutani, Hiroaki and Dunnington, Dewey and Posit and PBC},
  year = {2023},
  month = oct,
  urldate = {2023-11-08},
  abstract = {A system for 'declaratively' creating graphics, based on "The Grammar of Graphics". You provide the data, tell 'ggplot2' how to map variables to aesthetics, what graphical primitives to use, and it takes care of the details.},
  copyright = {MIT + file LICENSE},
  keywords = {Phylogenetics,Spatial,TeachingStatistics}
}
